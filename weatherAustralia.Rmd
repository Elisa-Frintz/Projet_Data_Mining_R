---
title: "Rain Australia"
output:
  pdf_document: default
  word_document: default
---

Notre jeu de données présente des relevés météorologiques en fonction de diverses villes en Australie.

Dans un premier temps nous ferons des analyses préliminaires afin d'en sortir des informations pertinentes qui nous permettrons de construire au mieux notre jeu de données.

La variable cible étant "RainTomorrow", nous lancerons plusieurs algorithmes de machine learning afin de prédire s'il pleuvra ou non le lendemain. Nous estimerons notre prédiction avec une matrice de confusion et divers estimateurs.

Pour information :
RainToday / RainTomorrow = Yes si Rainfall > 1.

#############################
                        
Import des libraries

#############################

```{r setup, include=TRUE}

library(readxl)
library(tidyverse)
library(PCAmixdata)
library(ggcorrplot)
library(ggplot2)
library(glmnet)
library(caret)
library(tidytable)
library(e1071)
library(ROSE)

```

############################################

Chargement et visualisation des données

############################################

```{r}

aus <- read.csv("weatherAUS.csv", header = TRUE, stringsAsFactors = TRUE)
head(aus)

```

#######################

Résumé des données

#######################

```{r}

summary(aus)

```

#################################

Trie du jeu de données par date

#################################

```{r}

aus <- aus[order(aus$Date),]

```

###################################################################

Suppression des variables avec un % trop important de valeur "NA"

###################################################################

```{r}

# Suppression des variables avec env. 50% de données manquantes. Remplacer les NA par des moyennes ou médianes amènerait un effet aléatoire aux variables. Nous perdrions de la pertinence sur notre jeu de données.
aus <- subset(aus, select = -c(Evaporation,Sunshine, Cloud3pm, Cloud9am))

```

##################################

Traitement des données manquantes

##################################

```{r}

colSums(is.na(aus))

```
```{r}

# Suppression des dernières valeurs manquantes
aus <- drop_na(aus)

# Vérification que nous n'avons plus de NA
colSums(is.na(aus))

```

##########################################

Description des données après nettoyage

##########################################

```{r}

summary(aus)

```

Une fois les valeurs manquantes traitées, nous remarquons que nous sommes dans un contexte avec des données déséquilibrées. Nous pourrons de ce fait utiliser des techniques d'échantillonage qui nous permettront d'équilibrer celui-ci.

####################

Gestion de la date

####################

```{r}

################# A GARDER ? ####################

# Gestion de la date
aus <- aus %>% dplyr::mutate(Year = lubridate::year(Date), Month = lubridate::month(Date), Day = lubridate::day(Date))
aus <- subset(aus, select = -c(Date))
summary(aus)

```


```{r}

head(aus)

```

####################################

Quelques statistiques descriptives

####################################

```{r}

#aus$RainToday <- ifelse(aus$RainToday == "Yes", 1, 0)

# Séparation du modèle :
X_aus <- subset(aus, select = -c(RainTomorrow))
y_aus <- aus$RainTomorrow

# Split quanti/quali
split <- splitmix(X_aus)

#Matrices de corrélation
mcor <- cor(split$X.quanti)
mcor

```

```{r}

# Corrélogramme avec corrplot
library(corrplot)
corrplot(mcor, type="upper", order="hclust", tl.col="black", tl.srt=45)

```

Avec le corrélogramme nous pouvons voir plus facilement que les variables liées à la température sont fortement corrélées.
Les variables "Pressure9pm" et "Pressure3am" sont fortement liées aussi.

Il est évident de relever aussi que "MaxTemp"/"Temp3pm" et "MinTemp"/"Temp9am" ont une relation. Nous pouvons supprimer les variables "MaxTemp" et "MinTemp" qui vont amener la même information que les 2 autres.

```{r}

# Suppression des variables MaxTemp, MinTemp
aus <- subset(aus, select = -c(MaxTemp, MinTemp))

```

Une question se pose sur la variable RainFall :

```{r}

boxplot(aus$Rainfall)

```

En effet le boxplot aussi peu visible soit-il, semble rapporter de nombreux outliers.

```{r}

#aus <- subset(aus, select = -c(Rainfall))

```

Nous supprimons les variables de dates

```{r}

aus <- subset(aus, select = -c(Year, Month, Day))

```


###################################

Centrage et reduction des données

###################################

```{r}

# Séparation données quanti / quali
split <- splitmix(aus)

# Centrage et réduction des données quanti
aus_scaled <- as.data.frame(scale(split$X.quanti, center = T))

# Refonte du dataset pour avoir les quali et quanti
aus <- cbind(split$X.quali, aus_scaled)

# Définition des X et y
X <- subset(aus, select = -c(RainTomorrow))
y <- aus$RainTomorrow

# Recodage des variables quali
X <- get_dummies.(X, drop_first = TRUE)

# X définitif
X <- subset(X, select = -c(Location, WindGustDir, WindDir9am, WindDir3pm, RainToday))

# Affichage pour vérification
head(X)

```

###############################

Séparation des données

###############################

```{r}

# Split train/test
X_train <- as.matrix(X[1:79050,])
X_test <- as.matrix(X[79051:112925,])

y_train <- as.matrix(y[1:79050])
y_test <- as.matrix(y[79051:112925])

```


##################################

Régression logistique Elasticnet

##################################

```{r}
'
# Régression logistique pénalisée Elasticnet
modele <- glmnet(x = X_train, y = y_train, family = "binomial", alpha = 0.5, standardize = FALSE)
plot(modele, xvar="lambda")

# Nombre de variables sélectionnées vs. lambda avec alpha = 0.5
print(cbind(modele$lambda, modele$df))

# Coefficients pour la 41ème valeur de lambda
print(modele$beta[,41])

# Coefficients non nul pour la 41ème valeur de lambda
print(modele$beta[abs(modele$beta[,15])>0,15])

# Prédiction
prediction <- predict(modele, X_test, type = "class", s=c(0))

# Matrice de confusion
mc <-  confusionMatrix(factor(prediction), factor(y_test))
print(mc)
'

```

#############################

 I) Support Vector Machines

#############################

Les SVM présentent un problème face aux nombres de variables que nous possédons dû au recodage des variables qualitatives. L'algorithme avec ses paramètres par défaut et après 1h de traitement n'était toujours pas terminé.
De ce fait, les variables qualitatives n'ont pas été conservées pour les SVM.

Afin d'équilibrer notre jeu de données et d'accélérer notre algorithme, nous partons sur une stratégie de sous échantillonage avec la librairie "ROSE".

##################

 a) SVM Linéaire

##################


```{r}

# Recodage des y_train
y_train_svm <- ifelse(y_train == "Yes", 1, 0)

#Recodage y_test
y_test_svm <- ifelse(y_test == "Yes", 1, 0)

# df train pour SVM
X_df <- data.frame(X_train)
train_svm <- X_df[,1:10]
train_svm <- cbind(train_svm, X_df$RainToday_Yes)
train_svm <-cbind(train_svm, y_train_svm)
colnames(train_svm)[11:12] <- c("RainToday", "RainTomorrow")

# df test pour SVM
test_df <- data.frame(X_test)
test_svm <- test_df[,1:10]
test_svm <- cbind(test_svm, test_df$RainToday_Yes)
colnames(test_svm)[11] <- "RainToday"

# Undersampling
under_train_svm <- ovun.sample(RainTomorrow~., data=train_svm, p=0.5, seed=5, method="under")$data
print(table(under_train_svm$RainTomorrow))

#Construction d'une solution pour tester plusieurs paramètres sans utiliser la validation croisée
cost = c(1, 10)
epsilon = c(0.05, 0.5)

for(i in cost){
  for(j in epsilon){
    svm_fit_linear <- svm(formula = RainTomorrow~., data = under_train_svm, kernel = "linear", type = "C-classification", scale = FALSE, cost = i, epsilon = j)
    
    # Prédiction
    pred_linear <- predict(svm_fit_linear, test_svm, type = "class")
    
    # Matrice de confusion, hyper-paramètres et estimateurs
    mc_linear <-  confusionMatrix(pred_linear, factor(y_test_svm))
    print(svm_fit_linear$call)
    cat("\n")
    cat("#################################\n")
    cat("Hyper-paramètres : \n")
    cat("Cost = ", i,"\n")
    cat("Epsilon", j, "\n")
    cat("#################################\n")
    cat("Matrice de confusion : \n")
    print(mc_linear$table)
    cat("#################################\n")
    cat("Accuracy : ",round(mc_linear$overall[1]*100,2) ,"%\n")
    cat("F1 score : ",round(mc_linear$byClass[7]*100,2) ,"%\n")
    cat("\n\n")
  }
}

```
Avec ces premiers résultats, nous observons que les hyper-paramètres du SVM linéaire changent peu les résultats.


##################

 b) SVM radial

##################

```{r}

# Ajout de l'hyper-paramètre gamma
gamma = c(0.1, 1)

for(i in cost){
  for(j in gamma){
    # Fit avec un kernel radial
    svm_fit_rad <- svm(formula = RainTomorrow~., data = under_train_svm, kernel = "radial", type = "C-classification", scale = FALSE, cost = i, gamma = j)
      
    # Prédiction
    pred_rad <- predict(svm_fit_rad, test_svm, type = "class")
    
    # Matrice de confusion, hyper-paramètres et estimateurs
    mc_radial <-  confusionMatrix(pred_rad, factor(y_test_svm))
    print(svm_fit_rad$call)
    cat("\n")
    cat("#################################\n")
    cat("Hyper-paramètres : \n")
    cat("Cost = ", i,"\n")
    cat("Gamma", j, "\n")
    cat("#################################\n")
    cat("Matrice de confusion : \n")
    print(mc_radial$table)
    cat("#################################\n")
    cat("Accuracy : ",round(mc_radial$overall[1]*100,2) ,"%\n")
    cat("F1 score : ",round(mc_radial$byClass[7]*100,2) ,"%\n")
    cat("\n\n")
  }
}


```


####################

 c) SVM polynomial

####################

Puis avec un noyau polynomial de degré 2.

```{r}

# Ajout de l'hyper-paramètre degree, coef0
degree = 2
coef0 = c(0.1, 1)

for(i in cost){
  for(j in gamma){
    for(k in degree){
      for(l in coef0){
        # Fit avec un kernel linéaire
        svm_fit_poly <- svm(formula = RainTomorrow~., data = under_train_svm, kernel = "polynomial", type = "C-classification", scale = FALSE, cost = i, gamma = j, degree = k, coef0 = l)

        # Prédiction
        pred_poly <- predict(svm_fit_poly, test_svm, type = "class")
        
        # Matrice de confusion
        mc_poly <-  confusionMatrix(pred_poly, factor(y_test_svm))
        print(svm_fit_poly$call)
        cat("\n")
        cat("#################################\n")
        cat("Hyper-paramètres : \n")
        cat("Cost = ", i,"\n")
        cat("Gamma = ", j, "\n")
        cat("Nombre de degrés = ", k, "\n")
        cat("Coef0 = ", k, "\n")
        cat("#################################\n")
        cat("Matrice de confusion : \n")
        print(mc_poly$table)
        cat("#################################\n")
        cat("Accuracy : ",round(mc_poly$overall[1]*100,2) ,"%\n")
        cat("F1 score : ",round(mc_poly$byClass[7]*100,2) ,"%\n")
        cat("\n\n")
      }
    }
  }
}

```

Etant donnée que nous sommes sur un jeu de données avec une série temporelle, nous ne pouvons utiliser la méthode tune pour chercher les meilleurs paramètres. En effet, la méthode tune utilise une validation croisée. Nous ne pouvons pas utiliser de validation croisée en série temporelle étant donnée que la donnée antérieure va impacter la donnée suivante.



